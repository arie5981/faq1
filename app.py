# ============================================
#   ×¢×•×–×¨ ××ª×¨ ××™×™×¦×’×™× â€“ ×’×¨×¡×” ×œ-Streamlit
#   (×§×•×“ ×¡×•×¤×™: ×ª×™×§×•×Ÿ ×©×’×™××•×ª ×§×¨×™×¡×” ×‘×××¦×¢×•×ª Try/Except ×¡×‘×™×‘ Embeddings)
# ============================================

import streamlit as st
import os
import re
import unicodedata
from dataclasses import dataclass
from typing import List, Optional
from rapidfuzz import fuzz, process

# ×™×™×‘×•× ×¡×¤×¨×™×•×ª ×”-OpenAI ×•×”-LangChain
import openai
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
import json 

# ============================================
#   ×”×’×“×¨×ª ××¤×ª×— OpenAI ×Ö¾Streamlit Secrets
# ============================================
try:
    openai_api_key = st.secrets["OPENAI_API_KEY"]
except KeyError:
    st.error("âŒ ×—×¡×¨ ××¤×ª×— OPENAI_API_KEY ×‘Ö¾Streamlit Secrets.")
    st.stop()

os.environ["OPENAI_API_KEY"] = openai_api_key

# ============================================
#   ××©×ª× ×” ×’×œ×•×‘×œ×™ ×œ×§×™×©×•×¨×™×
# ============================================
GLOBAL_CONTACT_DETAILS = {}


# ============================================
#   ×”×’×“×¨×•×ª ×¢××•×“ ×•Ö¾CSS ×œÖ¾RTL + ×¢×™×¦×•×‘ ×¡×•×¤×™
# ============================================
st.set_page_config(page_title="×ª××™×›×” ×œ××ª×¨ ××™×™×¦×’×™×", layout="wide")

# ğŸ¯ ×‘×œ×•×§ CSS ××ª×•×§×Ÿ ×•×‘×“×•×§ ×œ×¤×ª×¨×•×Ÿ ×‘×¢×™×•×ª ×”×™×™×©×•×¨ ×•×”××¨×•×•×—×™×
st.markdown("""
<style>
html, body, [class*="css"]  {
    direction: rtl;
    text-align: right;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
}

/* ×©×•×¨×ª ×›×•×ª×¨×ª ×¢×œ×™×•× ×” */
.header-bar {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 0.8rem 1.2rem;
    border-bottom: 1px solid #333;
}

/* ×œ×•×’×• */
.header-logo {
    height: 48px;
}

/* ×˜×§×¡×˜ ×œ×™×“ ×”×œ×•×’×• */
.header-text-main {
    font-weight: 700;
    font-size: 1.2rem;
    color: #3b82f6; /* ×›×—×•×œ */
}
.header-text-sub {
    font-weight: 500;
    font-size: 0.95rem;
    color: #38bdf8; /* ×ª×›×œ×ª */
}

/* ×‘×•×¢×ª ×©××œ×” */
.user-bubble {
    background-color: #e5e5e5;
    padding: 0.8rem 1rem;
    border-radius: 18px;
    margin: 0.2rem 0 0.4rem 0;
    display: inline-block;
}

/* ×˜×§×¡×˜ ×ª×©×•×‘×” */
.assistant-text {
    margin: 0.2rem 0 0 0; 
}

/* ×ª×™×‘×ª ×”×§×œ×˜ */
.question-box {
    position: relative;
    margin-top: 1rem;
    padding-top: 0.5rem;
    border-top: 1px solid #333;
}

/* ×”×¡×ª×¨×ª ×›×¤×ª×•×¨ "×©×œ×—" ×©×œ ×”×˜×•×¤×¡ */
div[data-testid="stForm"] div.stButton button {
    visibility: hidden; 
    width: 0.1px;
    padding: 0;
    margin: 0;
    height: 0.1px;
}

/* ğŸ’¡ CSS ×œ×©×™× ×•×™ ×¢×™×¦×•×‘ ×”×›×¤×ª×•×¨×™×: ×§×˜×Ÿ ×™×•×ª×¨ ×•×¦××•×“ */
div.stButton button { 
    /* ×¢×™×¦×•×‘ ×›×¤×ª×•×¨ ×”×ª×©×•×‘×” ×”×§×˜×Ÿ */
    height: 25px; /* ×’×•×‘×” × ××•×š ×™×•×ª×¨ */
    line-height: 1;
    padding: 2px 8px; /* ×¦××¦×•× Padding ×× ×›×™ */
    font-size: 0.8rem;
    border-radius: 4px;
    background-color: #3b82f6; /* ×›×—×•×œ */
    color: white;
    border: none;
    white-space: nowrap;
    width: auto; 
    margin: 0;
}
div.stButton button:hover {
    background-color: #2563eb;
}

/* ============================================================= */
/* ğŸ¯ ×ª×™×§×•×Ÿ ×¡×•×¤×™ ×œ××™×§×•× ×”×›×¤×ª×•×¨: ×“×¨×™×¡×ª Flexbox ×©×œ Streamlit */
/* ============================================================= */
[data-testid="stColumn"] {
    display: flex !important;
    flex-direction: row !important; 
    align-items: center !important; 
    gap: 0.5rem !important; 
}

/* ğŸ’¡ ×¢×‘×•×¨ ×”×˜×•×¨ ×©×œ ×”×›×¤×ª×•×¨ (×”×˜×•×¨ ×”×©× ×™, nth-child(2)), × ×¦××™×“ ××ª ×”×ª×•×›×Ÿ ×©×œ×• ×œ×™××™×Ÿ (Flex-End) */
[data-testid="stColumn"]:nth-child(2) > div {
    display: flex;
    justify-content: flex-end; 
    align-items: center;
    width: 100%; 
    padding: 0 !important;
}

/* ×•×“× ×©×”×˜×§×¡×˜ ×‘×˜×•×¨ ×©×œ ×”×©××œ×” (×”×¨××©×•×Ÿ) ××™×•×©×¨ ×œ×™××™×Ÿ */
[data-testid="stColumn"]:nth-child(1) > div {
    text-align: right;
    padding: 0 !important;
}

/* ============================================================= */
/* ğŸ¯ ×ª×™×§×•×Ÿ ×¡×•×¤×™ ×œ××¨×•×•×—×™×: ×“×¨×™×¡×” ××’×¨×¡×™×‘×™×ª ×©×œ ×’×•×‘×” ×”×©×•×¨×” */
/* ============================================================= */

/* ×§×•× ×˜×™×™× ×¨ ×”×¢××•×“×•×ª ×”×¨××©×™ - ×¦××¦×•× Margin ×‘×™×Ÿ ×”×©×•×¨×•×ª */
.st-emotion-cache-1r6r8qj { 
    margin-bottom: 0.25rem !important; 
    padding-bottom: 0px !important; 
    padding-top: 0px !important;
}

/* ×¦××¦×•× padding ×•-line-height ×‘×ª×•×š ×”-Markdown ×©×œ ×”×©××œ×” */
.st-emotion-cache-1c9v68d { 
    padding-top: 0rem !important;
    padding-bottom: 0rem !important;
    line-height: 1.2 !important; 
    margin: 0 !important;
}

</style>
""", unsafe_allow_html=True)

# ============================================
#   ×›×•×ª×¨×ª ×¢×œ×™×•× ×” ×¢× ×œ×•×’×• ×•×˜×§×¡×˜
# ============================================
logo_url = "https://raw.githubusercontent.com/arie5981/faq1/main/logobtl.png"

# ×ª×™×§×•×Ÿ ×©×’×™××ª ×¡×™× ×˜×§×¡: ×©×™××•×© ×‘-.format
st.markdown(
    """
<div class="header-bar">
  <div style="display:flex; align-items:center; gap:0.6rem;">
    <img src="{logo_url_placeholder}" class="header-logo" alt="×œ×•×’×• ×”×‘×™×˜×•×— ×”×œ××•××™" />
    <div style="display:flex; flex-direction:column;">
      <span class="header-text-main">×”×‘×™×˜×•×— ×”×œ××•××™</span>
      <span class="header-text-sub">×ª××™×›×” ×œ××ª×¨ ××™×™×¦×’×™× ×‘×’×‘×™×™×”</span>
    </div>
  </div>
</div>
""".format(logo_url_placeholder=logo_url),
    unsafe_allow_html=True,
)

# ============================================
#   ×§×¨×™××ª ×§×•×‘×¥ faq.txt ××ª×•×š ×”×¨×™×¤×•
# ============================================
FAQ_PATH = "faq.txt"

def read_txt_utf8(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

try:
    raw_faq = read_txt_utf8(FAQ_PATH)
except FileNotFoundError:
    st.error(f"âŒ ×§×•×‘×¥ FAQ ×œ× × ××¦× ×‘× ×ª×™×‘: {FAQ_PATH}. ×•×“× ×©×”×§×•×‘×¥ × ××¦× ×‘×ª×™×§×™×™×” ×”× ×›×•× ×”.")
    st.stop()


# ============================================
#   ×¢×™×‘×•×“ ×”-FAQ ×•×¨×™×›×•×– ×”×§×™×©×•×¨×™×
# ============================================
def normalize_he(s: str) -> str:
    if not s:
        return ""
    s = unicodedata.normalize("NFC", s)
    s = re.sub(r"[\u200e\u200f]", "", s)
    s = re.sub(r"[^\w\s\u0590-\u05FF]", " ", s)
    s = re.sub(r"\s+", " ", s).strip().lower()
    return s

@dataclass
class FAQItem:
    question: str
    variants: List[str]
    answer: str
    instruction: Optional[str] = None
    contact_details: Optional[dict] = None 

def parse_faq_new(text: str) -> List[FAQItem]:
    items = []
    
    global GLOBAL_CONTACT_DETAILS
    GLOBAL_CONTACT_DETAILS.clear() 

    # 1. ×—×™×œ×•×¥ ×›×œ ×”×§×™×©×•×¨×™× ×”×’×œ×•×‘×œ×™×™× ××›×œ ×”×˜×§×¡×˜
    all_c_matches = re.findall(r">>([^:]+?)\s*:\s*([^<]+?)<<", text)
    GLOBAL_CONTACT_DETAILS = {k.strip(): v.strip() for k, v in all_c_matches}
    
    # 2. ×”×¡×¨×ª ×›×œ ×”×‘×œ×•×§×™× ×©×œ ×”×§×™×©×•×¨×™× ×”×’×œ×•×‘×œ×™×™× ××˜×§×¡×˜ ×”-FAQ
    text_without_links = re.sub(r">>([^:]+?)\s*:\s*([^<]+?)<<", "", text)
    
    # 3. ×¤×™×¦×•×œ ×œ×‘×œ×•×§×™× ×©×œ ×©××œ×•×ª
    blocks = re.split(r"(?=×©××œ×”\s*:)", text_without_links) 

    for b in blocks:
        b = b.strip()
        if not b:
            continue

        q_match = re.search(r"×©××œ×”\s*:\s*(.+)", b)
        v_match = re.search(r"(?s)× ×™×¡×•×—×™× ×“×•××™×\s*:\s*(.+?)(?:\n×ª×©×•×‘×”\s*:|\Z)", b)
        a_match = re.search(r"(?s)×ª×©×•×‘×”\s*:\s*(.+?)(?:\n×”×•×¨××”\s*:|\Z)", b)
        i_match = re.search(r"(?s)×”×•×¨××”\s*:\s*(.+?)(?:\n>>|\Z)", b)
        
        question = q_match.group(1).strip() if q_match else ""
        
        answer = ""
        if a_match:
            raw_answer_content = a_match.group(1)
            lines = raw_answer_content.splitlines()
            cleaned_lines = [line.strip() for line in lines]
            answer = '\n'.join(cleaned_lines).strip()
            
        variants = []
        if v_match:
            raw = v_match.group(1)
            variants = [s.strip(" -\t") for s in raw.split("\n") if s.strip()]

        instruction = i_match.group(1).strip() if i_match else None
        
        items.append(FAQItem(question, variants, answer, instruction, contact_details={}))

    return items

faq_items = parse_faq_new(raw_faq)

# === ×™×¦×™×¨×ª Embeddings + FAISS ===
# ×™×¦×™×¨×ª ××©×ª× ×” ×’×œ×•×‘×œ×™ ×œ××—×¡×•×Ÿ ×”-FAISS
faq_store = None

# ğŸ¯ ×”×’× ×ª Try/Except ×¡×‘×™×‘ ××ª×—×•×œ OpenAI/FAISS
try:
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small", api_key=openai_api_key)

    docs = []
    for i, item in enumerate(faq_items):
        merged = " | ".join([item.question] + item.variants)
        docs.append(Document(page_content=merged, metadata={"idx": i}))

    faq_store = FAISS.from_documents(docs, embeddings)
    st.session_state.embeddings_ready = True 
except Exception as e:
    # ×× ×”×—×™×‘×•×¨/××ª×—×•×œ × ×›×©×œ, × ×œ×›×•×“ ××ª ×”×©×’×™××”, × ×“×•×•×— ×¢×œ×™×”, ×•× ××©×™×š ×œ×¨×•×¥
    st.error(f"âŒ ×©×’×™××” ×—××•×¨×”: ×™×¦×™×¨×ª ××•×“×œ ×”×—×™×¤×•×© × ×›×©×œ×”. ×”××¤×œ×™×§×¦×™×” ×ª×¤×¢×œ ×‘××¦×‘ ×—×™×¤×•×© ×¤××–×™ ×‘×œ×‘×“. ×™×™×ª×›×Ÿ ×©×™×© ×‘×¢×™×” ×‘××¤×ª×— ×”-OpenAI. ×©×’×™××”: {e}")
    st.session_state.embeddings_ready = False
    faq_store = None # ×•×“× ×©×”××©×ª× ×” × ×©××¨ None ×‘××§×¨×” ×©×œ ×›×©×œ


# ============================================
#   ×¤×•× ×§×¦×™×” ×œ×¢×™×‘×•×“ ×ª×•×›×Ÿ ×”×ª×©×•×‘×” (××©×ª××©×ª ×‘×’×œ×•×‘×œ×™)
# ============================================
def process_answer_content(item: FAQItem) -> str:
    global GLOBAL_CONTACT_DETAILS 
    
    answer_text = item.answer.strip()
    
    # 2. ×”×—×œ×¤×ª ××™×œ×•×ª ××¤×ª×— ×‘×§×™×©×•×¨×™ Markdown ×‘×ª×•×š ×”-ANSWER
    if GLOBAL_CONTACT_DETAILS:
        for key, value in GLOBAL_CONTACT_DETAILS.items():
            markdown_link = f"[{key}]({value})"
            answer_text = answer_text.replace(f"[{key}]", markdown_link)
        
        
    # 3. ×˜×™×¤×•×œ ×‘×©×“×” '×”×•×¨××”' ×•×”×•×¡×¤×ª×• ×‘×¡×•×£
    if item.instruction: 
        instruction = item.instruction
        
        # 3×. ×”×—×œ×¤×ª ××™×œ×•×ª ××¤×ª×— ×‘×§×™×©×•×¨×™ Markdown ×‘×ª×•×š ×”×”×•×¨××”
        for key, value in GLOBAL_CONTACT_DETAILS.items():
            markdown_link = f"[{key}]({value})"
            instruction = instruction.replace(f"[{key}]", markdown_link)
        
        answer_text += f"\n\n**×”×¢×¨×•×ª ×•×”×•×¨××•×ª:** {instruction}"

    # ×”×•×¡×¤×ª \n\n ×‘×™×Ÿ ×¤×¡×§××•×ª
    final_content = answer_text.replace('\n', '\n\n')
    return final_content


# ============================================
#   ×—×™×¤×•×© FAQ â€“ fuzzy + embeddings
# ============================================

def search_faq(query: str) -> str:
    nq = normalize_he(query)

    # --- ×—×™×¤×•×© ×¤××–×™ ×¢×œ ×©××œ×•×ª ×•× ×™×¡×•×—×™× ---
    scored = []
    for i, item in enumerate(faq_items):
        all_texts = [item.question] + item.variants
        for t in all_texts:
            score = fuzz.token_sort_ratio(nq, normalize_he(t))
            scored.append((score, i, t))

    scored.sort(reverse=True, key=lambda x: x[0])
    best_score, best_idx, _ = scored[0]

    if best_score >= 80:
        item = faq_items[best_idx]
        final_content = process_answer_content(item)
        return f"{final_content}\n\n××§×•×¨: faq\n\n×©××œ×” ××–×•×”×”: {item.question}"

    # --- fallback: embeddings (×¢× ×©×™×¤×•×¨ × ×™×§×•×“) ---
    # ğŸ¯ ×‘×“×™×§×” ×”×× ×”××•×“×œ ××•×›×Ÿ
    if not st.session_state.embeddings_ready:
        return "×œ× × ××¦××” ×ª×©×•×‘×” ×‘×—×™×¤×•×© ×¤××–×™. ×”×—×™×¤×•×© ×”×¡×× ×˜×™ ××™× ×• ×¤×¢×™×œ ×¢×§×‘ ×©×’×™××ª ×”×ª×—×‘×¨×•×ª ×œ-OpenAI. × ×¡×” ×œ× ×¡×— ××ª ×”×©××œ×” ××—×“×©."

    hits = faq_store.similarity_search_with_score(query, k=5)
    
    boosted_hits = []
    for doc, score in hits:
        idx = doc.metadata["idx"]
        item = faq_items[idx]
        fuzzy_score = fuzz.token_sort_ratio(nq, normalize_he(item.question))
        boosted_score = (score * 0.7) + (1.0 - (fuzzy_score / 100)) * 0.3
        boosted_hits.append((doc, boosted_score, idx))

    boosted_hits.sort(key=lambda x: x[1])
    
    best_doc, best_score, best_idx = boosted_hits[0]

    if best_score <= 1.1: 
        result_item = faq_items[best_idx]
        
        final_content = process_answer_content(result_item)

        similar_questions = [
            faq_items[d.metadata["idx"]].question
            for d, s, _ in boosted_hits[1:4] 
            if s <= 1.3 and faq_items[d.metadata["idx"]].question.strip() != result_item.question.strip()
        ][:3]
        
        if similar_questions:
            sq_json = json.dumps(similar_questions, ensure_ascii=False)
            final_content += f"\n\n---SIMILAR_QUESTIONS---{sq_json}"

        return f"{final_content}\n\n××§×•×¨: faq\n\n×©××œ×” ××–×•×”×” (×¡×× ×˜×™): {result_item.question}"

    return "×œ× × ××¦××” ×ª×©×•×‘×”, × ×¡×” ×œ× ×¡×— ××ª ×”×©××œ×” ××—×“×©."

# ============================================
#   ×¤×•× ×§×¦×™×™×ª Callback ×œ×˜×™×¤×•×œ ×‘×©×œ×™×—×ª ×”×˜×•×¤×¡ / ×œ×—×™×¦×” ×¢×œ ×©××œ×”
# ============================================
def handle_submit(query_text=None):
    if query_text is None:
        query = st.session_state.query_input
    else:
        query = query_text

    if query:
        st.session_state.messages.append({"role": "user", "content": query})
        answer = search_faq(query)
        st.session_state.messages.append({"role": "assistant", "content": answer})
        st.session_state.query_input = "" 


# ============================================
#   × ×™×”×•×œ ×©×™×—×” ×›××• ChatGPT
# ============================================
if "messages" not in st.session_state:
    st.session_state.messages = []
    
# ğŸ¯ ×”×•×¡×¤×ª ×‘×“×™×§×” ×œ××¦×‘ Embeddings ×‘-session_state
if "embeddings_ready" not in st.session_state:
    st.session_state.embeddings_ready = False

# ×©××œ×•×ª × ×¤×•×¦×•×ª ×œ××¡×š ×”×¨××©×•×Ÿ
POPULAR_QUESTIONS = [
    "××™×š ××•×¡×™×¤×™× ××©×ª××© ×—×“×© ×‘××ª×¨ ××™×™×¦×’×™×.",
    "××§×‘×œ ×”×•×“×¢×” ×©××—×“ ××• ×™×•×ª×¨ ×× ×ª×•× ×™ ×”×”×–×“×”×•×ª ×©×’×•×™×™×.",
    "××™×š ×™×•×¦×¨×™× ×§×™×¦×•×¨ ×“×¨×š ×œ××ª×¨ ××™×™×¦×’×™× ×¢×œ ×©×•×œ×—×Ÿ ×”×¢×‘×•×“×”.",
    "×¨×•×¦×” ×œ×§×‘×œ ××ª ×”×§×•×“ ×”×—×“ ×¤×¢××™ ×œ×“×•××¨ ××œ×§×˜×¨×•× ×™.",
]

st.markdown("")

# ----------------------------------------------------
# ğŸ’¡ ×”×¦×’×ª ×©××œ×•×ª × ×¤×•×¦×•×ª ×›×¨×©×™××” ×××•×¡×¤×¨×ª ×¢× ×›×¤×ª×•×¨ ×§×˜×Ÿ
# ----------------------------------------------------
if len(st.session_state.messages) == 0:
    st.markdown("### ×©××œ×•×ª × ×¤×•×¦×•×ª:")
    
    for i, q in enumerate(POPULAR_QUESTIONS, start=1):
        # ğŸ’¡ ×—×œ×•×§×” ×œ-2 ×¢××•×“×•×ª: ×©××œ×” (80%), ×›×¤×ª×•×¨ (20%) ×¢× gap="small"
        col_q, col_btn = st.columns([0.8, 0.2], gap="small")
        
        with col_q:
            # ğŸ’¡ ×”×¦×’×ª ×”×©××œ×” ×›×—×œ×§ ××¨×©×™××” ×××•×¡×¤×¨×ª
            st.markdown(f"**{i}.** {q}", unsafe_allow_html=True)
            
        with col_btn:
             # ğŸ’¡ ×›×¤×ª×•×¨ ×§×˜×Ÿ ×©×™×•×¦××“ ×œ×©××œ×”
            st.button(
                "×œ×ª×©×•×‘×”", 
                key=f"popular_q_{i}", 
                on_click=handle_submit, 
                args=(q,)
            )

    st.markdown("## ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?")
    st.markdown("")

# ----------------------------------------------------
# ×ª×™×‘×ª ×”×§×œ×˜
# ----------------------------------------------------
st.markdown('<div class="question-box"></div>', unsafe_allow_html=True)

with st.form("ask_form", clear_on_submit=False): 
    query = st.text_input(" ", 
                          placeholder="×©××œ ×©××œ×” ×•×”×§×© Enter", 
                          key="query_input")
    
    submitted = st.form_submit_button("×©×œ×—", on_click=handle_submit)

# ----------------------------------------------------
# ××¤×¨×™×“ ×•×™×–×•××œ×™ ×‘×™×Ÿ ×˜×•×¤×¡ ×”×§×œ×˜ ×œ×”×™×¡×˜×•×¨×™×”
# ----------------------------------------------------
if len(st.session_state.messages) > 0:
    st.markdown("---") 

# =======================================================================
# ×”×¦×’×ª ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×” ×•×¨×©×™××ª ×©××œ×•×ª ×§×©×•×¨×•×ª
# =======================================================================

user_indices = [i for i, msg in enumerate(st.session_state.messages) if msg["role"] == "user"]

for user_idx in user_indices[::-1]:
    
    # 1. ×”×¦×’×ª ×”×•×“×¢×ª ×”×©××œ×”
    user_msg = st.session_state.messages[user_idx]
    st.markdown(f"""
<div class="user-bubble">
<strong>×©××œ×”:</strong> {user_msg['content']}
</div>
""", unsafe_allow_html=True)
    
    # 2. ×”×¦×’×ª ×”×•×“×¢×ª ×”×ª×©×•×‘×” (×× ×§×™×™××ª)
    assistant_idx = user_idx + 1
    if assistant_idx < len(st.session_state.messages):
        assistant_msg = st.session_state.messages[assistant_idx]
        raw_display_content = assistant_msg['content'] 
        
        similar_questions = []
        sq_match = re.search(r"---SIMILAR_QUESTIONS---(.*)", raw_display_content)
        
        if sq_match:
            try:
                sq_json_str = sq_match.group(1).strip()
                similar_questions = json.loads(sq_json_str)
                display_content = raw_display_content.replace(f"\n\n---SIMILAR_QUESTIONS---{sq_json_str}", "").strip()
            except json.JSONDecodeError:
                display_content = raw_display_content
        else:
            display_content = raw_display_content
            
        st.markdown(f"""
<div class="assistant-text">
<strong>×ª×©×•×‘×”:</strong>
</div>
""", unsafe_allow_html=True)
        
        st.markdown(display_content, unsafe_allow_html=True)

        # ğŸ’¡ ×”×¦×’×ª ×”×©××œ×•×ª ×”×§×©×•×¨×•×ª ×›×¨×©×™××” ×××•×¡×¤×¨×ª ×¢× ×›×¤×ª×•×¨ ×§×˜×Ÿ
        if similar_questions:
            st.markdown("---") 
            st.markdown("#### ×©××œ×•×ª ×§×©×•×¨×•×ª:")
            
            base_key = f"similar_q_{user_idx}" 
            
            for i, sq in enumerate(similar_questions, start=1):
                # ğŸ’¡ ×—×œ×•×§×” ×œ-2 ×¢××•×“×•×ª: ×©××œ×” (80%), ×›×¤×ª×•×¨ (20%) ×¢× gap="small"
                col_q, col_btn = st.columns([0.8, 0.2], gap="small")

                with col_q:
                    # ğŸ’¡ ×”×¦×’×ª ×”×©××œ×” ×›×—×œ×§ ××¨×©×™××” ×××•×¡×¤×¨×ª
                    st.markdown(f"**{i}.** {sq}", unsafe_allow_html=True)
                    
                with col_btn:
                    # ğŸ’¡ ×›×¤×ª×•×¨ ×§×˜×Ÿ ×©×™×•×¦××“ ×œ×©××œ×”
                    st.button(
                        "×œ×ª×©×•×‘×”", 
                        key=f"{base_key}_{i}", 
                        on_click=handle_submit, 
                        args=(sq,)
                    )
