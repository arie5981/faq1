# ============================================
#   ×¢×•×–×¨ ××ª×¨ ××™×™×¦×’×™× â€“ ×’×¨×¡×” ×œ-Streamlit
#   (××¢×•×“×›×Ÿ: ×¤×ª×¨×•×Ÿ ×¡×•×¤×™ ×œ××™×§×•× ×›×¤×ª×•×¨ ×•×¦××¦×•× ×¨×•×•×—×™×)
# ============================================

import streamlit as st
import os
import re
import unicodedata
from dataclasses import dataclass
from typing import List, Optional
from rapidfuzz import fuzz, process

import openai
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
import json 

# ============================================
#   ×”×’×“×¨×ª ××¤×ª×— OpenAI ×Ö¾Streamlit Secrets
# ============================================
try:
    openai_api_key = st.secrets["OPENAI_API_KEY"]
except KeyError:
    st.error("âŒ ×—×¡×¨ ××¤×ª×— OPENAI_API_KEY ×‘Ö¾Streamlit Secrets.\n×™×© ×œ×”×™×›× ×¡ ×œÖ¾Manage app â†’ Settings â†’ Secrets ×•×œ×”×•×¡×™×£:\nOPENAI_API_KEY = \"...\"")
    st.stop()

os.environ["OPENAI_API_KEY"] = openai_api_key

# ============================================
#   ××©×ª× ×” ×’×œ×•×‘×œ×™ ×œ×§×™×©×•×¨×™×
# ============================================
GLOBAL_CONTACT_DETAILS = {}


# ============================================
#   ×”×’×“×¨×•×ª ×¢××•×“ ×•Ö¾CSS ×œÖ¾RTL + ×¢×™×¦×•×‘ ×¢×“×™×Ÿ
# ============================================
st.set_page_config(page_title="×ª××™×›×” ×œ××ª×¨ ××™×™×¦×’×™×", layout="wide")

st.markdown("""
<style>
html, body, [class*="css"]  {
    direction: rtl;
    text-align: right;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
}

/* ×©×•×¨×ª ×›×•×ª×¨×ª ×¢×œ×™×•× ×” */
.header-bar {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 0.8rem 1.2rem;
    border-bottom: 1px solid #333;
}

/* ×œ×•×’×• */
.header-logo {
    height: 48px;
}

/* ×˜×§×¡×˜ ×œ×™×“ ×”×œ×•×’×• */
.header-text-main {
    font-weight: 700;
    font-size: 1.2rem;
    color: #3b82f6; /* ×›×—×•×œ */
}
.header-text-sub {
    font-weight: 500;
    font-size: 0.95rem;
    color: #38bdf8; /* ×ª×›×œ×ª */
}

/* ×‘×•×¢×ª ×©××œ×” */
.user-bubble {
    background-color: #e5e5e5;
    padding: 0.8rem 1rem;
    border-radius: 18px;
    margin: 0.2rem 0 0.4rem 0;
    display: inline-block;
}

/* ×˜×§×¡×˜ ×ª×©×•×‘×” */
.assistant-text {
    margin: 0.2rem 0 0 0; 
}

/* ×ª×™×‘×ª ×”×§×œ×˜ */
.question-box {
    position: relative;
    margin-top: 1rem;
    padding-top: 0.5rem;
    border-top: 1px solid #333;
}

/* ×”×¡×ª×¨×ª ×›×¤×ª×•×¨ "×©×œ×—" ×©×œ ×”×˜×•×¤×¡ */
div[data-testid="stForm"] div.stButton button {
    visibility: hidden; 
    width: 0.1px;
    padding: 0;
    margin: 0;
    height: 0.1px;
}

/* ğŸ’¡ CSS ×œ×©×™× ×•×™ ×¢×™×¦×•×‘ ×”×›×¤×ª×•×¨×™×: ×§×˜×Ÿ ×™×•×ª×¨ ×•××•×¦××“ ×œ×©××œ×” ×‘×¨×©×™××” */
div.stButton button { 
    /* ×¢×™×¦×•×‘ ×›×¤×ª×•×¨ ×”×ª×©×•×‘×” ×”×§×˜×Ÿ */
    height: 25px; /* ×’×•×‘×” × ××•×š ×™×•×ª×¨ */
    line-height: 1;
    padding: 2px 8px; /* ×¦××¦×•× Padding ×× ×›×™ */
    font-size: 0.8rem;
    border-radius: 4px;
    background-color: #3b82f6; /* ×›×—×•×œ */
    color: white;
    border: none;
    white-space: nowrap;
    width: auto; 
    margin: 0;
}
div.stButton button:hover {
    background-color: #2563eb;
}

/* ğŸ’¡ ×›×œ×œ ×§×¨×™×˜×™: ××›×¨×™×— ××ª ×”×˜×•×¨ ×©×œ ×”×›×¤×ª×•×¨ ×œ×”×ª×™×™×©×¨ ×œ×™××™×Ÿ (Flex-End) */
[data-testid="stColumn"] {
    display: flex;
    flex-direction: column;
    align-items: flex-end; 
}

/* ×•×“× ×©×”×˜×§×¡×˜ ×‘×ª×•×š ×”×˜×•×¨×™× × ×©××¨ ××™×•×©×¨ ×œ×™××™×Ÿ */
[data-testid="stColumn"] > div {
    width: 100%;
    text-align: right;
}

/* ğŸ’¡ ×›×œ×œ×™ ×¦××¦×•× ×¨×•×•×—×™× ×× ×›×™×™× ×‘×™×Ÿ ×”×©××œ×•×ª */
.st-emotion-cache-1r6r8qj { /* ×§×•× ×˜×™×™× ×¨ ×”×¢××•×“×•×ª ×”×¨××©×™ */
    margin-bottom: 0.5rem !important; /* ×¨×•×•×— ×§×˜×Ÿ ×‘×™×Ÿ ×”×©×•×¨×•×ª */
    padding-bottom: 0px !important; 
    padding-top: 0px !important;
}

/* ğŸ’¡ ×¦××¦×•× padding ×‘×ª×•×š ×”-Markdown ×©×œ ×”×©××œ×” */
.st-emotion-cache-1c9v68d { 
    padding-top: 0rem !important;
    padding-bottom: 0rem !important;
    line-height: 1.2; /* ×¦××¦×•× ×’×•×‘×” ×”×©×•×¨×” */
}

</style>
""", unsafe_allow_html=True)

# ============================================
#   ×›×•×ª×¨×ª ×¢×œ×™×•× ×” ×¢× ×œ×•×’×• ×•×˜×§×¡×˜
# ============================================
logo_url = "https://raw.githubusercontent.com/arie5981/faq1/main/logobtl.png"

st.markdown(
    f"""
<div class="header-bar">
  <div style="display:flex; align-items:center; gap:0.6rem;">
    <img src="{logo_url}" class="header-logo" alt="×œ×•×’×• ×”×‘×™×˜×•×— ×”×œ××•××™" />
    <div style="display:flex; flex-direction:column;">
      <span class="header-text-main">×”×‘×™×˜×•×— ×”×œ××•××™</span>
      <span class="header-text-sub">×ª××™×›×” ×œ××ª×¨ ××™×™×¦×’×™× ×‘×’×‘×™×™×”</span>
    </div>
  </div>
</div>
""",
    unsafe_allow_html=True,
)

# ============================================
#   ×§×¨×™××ª ×§×•×‘×¥ faq.txt ××ª×•×š ×”×¨×™×¤×•
# ============================================
FAQ_PATH = "faq.txt"

def read_txt_utf8(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

try:
    raw_faq = read_txt_utf8(FAQ_PATH)
except FileNotFoundError:
    st.error(f"âŒ ×§×•×‘×¥ FAQ ×œ× × ××¦× ×‘× ×ª×™×‘: {FAQ_PATH}. ×•×“× ×©×”×§×•×‘×¥ × ××¦× ×‘×ª×™×§×™×™×” ×”× ×›×•× ×”.")
    st.stop()


# ============================================
#   ×¢×™×‘×•×“ ×”-FAQ ×•×¨×™×›×•×– ×”×§×™×©×•×¨×™×
# ============================================
def normalize_he(s: str) -> str:
    if not s:
        return ""
    s = unicodedata.normalize("NFC", s)
    s = re.sub(r"[\u200e\u200f]", "", s)
    s = re.sub(r"[^\w\s\u0590-\u05FF]", " ", s)
    s = re.sub(r"\s+", " ", s).strip().lower()
    return s

@dataclass
class FAQItem:
    question: str
    variants: List[str]
    answer: str
    instruction: Optional[str] = None
    contact_details: Optional[dict] = None 

def parse_faq_new(text: str) -> List[FAQItem]:
    items = []
    
    global GLOBAL_CONTACT_DETAILS
    GLOBAL_CONTACT_DETAILS.clear() # ××™×¤×•×¡ ×”××™×œ×•×Ÿ ×”×’×œ×•×‘×œ×™

    # 1. ×—×™×œ×•×¥ ×›×œ ×”×§×™×©×•×¨×™× ×”×’×œ×•×‘×œ×™×™× ××›×œ ×”×˜×§×¡×˜
    all_c_matches = re.findall(r">>([^:]+?)\s*:\s*([^<]+?)<<", text)
    GLOBAL_CONTACT_DETAILS = {k.strip(): v.strip() for k, v in all_c_matches}
    
    # 2. ×”×¡×¨×ª ×›×œ ×”×‘×œ×•×§×™× ×©×œ ×”×§×™×©×•×¨×™× ×”×’×œ×•×‘×œ×™×™× ××˜×§×¡×˜ ×”-FAQ ×›×“×™ ×œ×× ×•×¢ ×”×¤×¨×¢×” ×œ× ×™×ª×•×— ×”×©××œ×•×ª
    text_without_links = re.sub(r">>([^:]+?)\s*:\s*([^<]+?)<<", "", text)
    
    # 3. ×¤×™×¦×•×œ ×œ×‘×œ×•×§×™× ×©×œ ×©××œ×•×ª
    blocks = re.split(r"(?=×©××œ×”\s*:)", text_without_links) 

    for b in blocks:
        b = b.strip()
        if not b:
            continue

        q_match = re.search(r"×©××œ×”\s*:\s*(.+)", b)
        v_match = re.search(r"(?s)× ×™×¡×•×—×™× ×“×•××™×\s*:\s*(.+?)(?:\n×ª×©×•×‘×”\s*:|\Z)", b)
        a_match = re.search(r"(?s)×ª×©×•×‘×”\s*:\s*(.+?)(?:\n×”×•×¨××”\s*:|\Z)", b)
        i_match = re.search(r"(?s)×”×•×¨××”\s*:\s*(.+?)(?:\n>>|\Z)", b)
        
        question = q_match.group(1).strip() if q_match else ""
        
        answer = ""
        if a_match:
            raw_answer_content = a_match.group(1)
            lines = raw_answer_content.splitlines()
            cleaned_lines = [line.strip() for line in lines]
            answer = '\n'.join(cleaned_lines).strip()
            
        variants = []
        if v_match:
            raw = v_match.group(1)
            variants = [s.strip(" -\t") for s in raw.split("\n") if s.strip()]

        instruction = i_match.group(1).strip() if i_match else None
        
        items.append(FAQItem(question, variants, answer, instruction, contact_details={}))

    return items

faq_items = parse_faq_new(raw_faq)

# === ×™×¦×™×¨×ª Embeddings + FAISS ===
embeddings = OpenAIEmbeddings(model="text-embedding-3-small", api_key=openai_api_key)

docs = []
for i, item in enumerate(faq_items):
    merged = " | ".join([item.question] + item.variants)
    docs.append(Document(page_content=merged, metadata={"idx": i}))

faq_store = FAISS.from_documents(docs, embeddings)


# ============================================
#   ×¤×•× ×§×¦×™×” ×œ×¢×™×‘×•×“ ×ª×•×›×Ÿ ×”×ª×©×•×‘×” (××©×ª××©×ª ×‘×’×œ×•×‘×œ×™)
# ============================================
def process_answer_content(item: FAQItem) -> str:
    global GLOBAL_CONTACT_DETAILS 
    
    answer_text = item.answer.strip()
    
    # 2. ×”×—×œ×¤×ª ××™×œ×•×ª ××¤×ª×— ×‘×§×™×©×•×¨×™ Markdown ×‘×ª×•×š ×”-ANSWER
    if GLOBAL_CONTACT_DETAILS:
        for key, value in GLOBAL_CONTACT_DETAILS.items():
            markdown_link = f"[{key}]({value})"
            answer_text = answer_text.replace(f"[{key}]", markdown_link)
        
        
    # 3. ×˜×™×¤×•×œ ×‘×©×“×” '×”×•×¨××”' ×•×”×•×¡×¤×ª×• ×‘×¡×•×£
    if item.instruction: 
        instruction = item.instruction
        
        # 3×. ×”×—×œ×¤×ª ××™×œ×•×ª ××¤×ª×— ×‘×§×™×©×•×¨×™ Markdown ×‘×ª×•×š ×”×”×•×¨××”
        for key, value in GLOBAL_CONTACT_DETAILS.items():
            markdown_link = f"[{key}]({value})"
            instruction = instruction.replace(f"[{key}]", markdown_link)
        
        answer_text += f"\n\n**×”×¢×¨×•×ª ×•×”×•×¨××•×ª:** {instruction}"

    # ×”×•×¡×¤×ª \n\n ×‘×™×Ÿ ×¤×¡×§××•×ª
    final_content = answer_text.replace('\n', '\n\n')
    return final_content


# ============================================
#   ×—×™×¤×•×© FAQ â€“ fuzzy + embeddings
# ============================================

def search_faq(query: str) -> str:
    nq = normalize_he(query)

    # --- ×—×™×¤×•×© ×¤××–×™ ×¢×œ ×©××œ×•×ª ×•× ×™×¡×•×—×™× ---
    scored = []
    for i, item in enumerate(faq_items):
        all_texts = [item.question]
