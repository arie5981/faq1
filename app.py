# ============================================
#   ×¢×•×–×¨ ××ª×¨ ××™×™×¦×’×™× â€“ ×’×¨×¡×” ×œ-Streamlit
#   (××¢×•×“×›×Ÿ: ×¤×ª×¨×•×Ÿ ×¡×•×¤×™ ×œ××™×§×•× ×›×¤×ª×•×¨ ×•×¦××¦×•× ×¨×•×•×—×™× + DEBUG PRINTS)
# ============================================

import streamlit as st
import os
import re
import unicodedata
from dataclasses import dataclass
from typing import List, Optional
from rapidfuzz import fuzz, process

import openai
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
import json 

# ============================================
#   ×”×’×“×¨×ª ××¤×ª×— OpenAI ×Ö¾Streamlit Secrets
# ============================================
print("DEBUG 1: ××ª×—×™×œ ×”×’×“×¨×ª ××¤×ª×—.")
try:
    openai_api_key = st.secrets["OPENAI_API_KEY"]
except KeyError:
    st.error("âŒ ×—×¡×¨ ××¤×ª×— OPENAI_API_KEY ×‘Ö¾Streamlit Secrets.\n×™×© ×œ×”×™×›× ×¡ ×œÖ¾Manage app â†’ Settings â†’ Secrets ×•×œ×”×•×¡×™×£:\nOPENAI_API_KEY = \"...\"")
    st.stop()

os.environ["OPENAI_API_KEY"] = openai_api_key
print("DEBUG 2: ××¤×ª×— OpenAI ×”×•×’×“×¨ ×‘×”×¦×œ×—×”.")

# ============================================
#   ××©×ª× ×” ×’×œ×•×‘×œ×™ ×œ×§×™×©×•×¨×™×
# ============================================
GLOBAL_CONTACT_DETAILS = {}


# ============================================
#   ×”×’×“×¨×•×ª ×¢××•×“ ×•Ö¾CSS ×œÖ¾RTL + ×¢×™×¦×•×‘ ×¢×“×™×Ÿ
# ============================================
st.set_page_config(page_title="×ª××™×›×” ×œ××ª×¨ ××™×™×¦×’×™×", layout="wide")
# [CSS × ×©××¨ ×œ×œ× ×©×™× ×•×™ ××”×ª×™×§×•×Ÿ ×”×§×•×“×]

st.markdown("""
<style>
html, body, [class*="css"]  {
    direction: rtl;
    text-align: right;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
}

/* ×©×•×¨×ª ×›×•×ª×¨×ª ×¢×œ×™×•× ×” */
.header-bar {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 0.8rem 1.2rem;
    border-bottom: 1px solid #333;
}

/* ×œ×•×’×• */
.header-logo {
    height: 48px;
}

/* ×˜×§×¡×˜ ×œ×™×“ ×”×œ×•×’×• */
.header-text-main {
    font-weight: 700;
    font-size: 1.2rem;
    color: #3b82f6; /* ×›×—×•×œ */
}
.header-text-sub {
    font-weight: 500;
    font-size: 0.95rem;
    color: #38bdf8; /* ×ª×›×œ×ª */
}

/* ×‘×•×¢×ª ×©××œ×” */
.user-bubble {
    background-color: #e5e5e5;
    padding: 0.8rem 1rem;
    border-radius: 18px;
    margin: 0.2rem 0 0.4rem 0;
    display: inline-block;
}

/* ×˜×§×¡×˜ ×ª×©×•×‘×” */
.assistant-text {
    margin: 0.2rem 0 0 0; 
}

/* ×ª×™×‘×ª ×”×§×œ×˜ */
.question-box {
    position: relative;
    margin-top: 1rem;
    padding-top: 0.5rem;
    border-top: 1px solid #333;
}

/* ×”×¡×ª×¨×ª ×›×¤×ª×•×¨ "×©×œ×—" ×©×œ ×”×˜×•×¤×¡ */
div[data-testid="stForm"] div.stButton button {
    visibility: hidden; 
    width: 0.1px;
    padding: 0;
    margin: 0;
    height: 0.1px;
}

/* ğŸ’¡ CSS ×œ×©×™× ×•×™ ×¢×™×¦×•×‘ ×”×›×¤×ª×•×¨×™×: ×§×˜×Ÿ ×™×•×ª×¨ ×•××•×¦××“ ×œ×©××œ×” ×‘×¨×©×™××” */
div.stButton button { 
    /* ×¢×™×¦×•×‘ ×›×¤×ª×•×¨ ×”×ª×©×•×‘×” ×”×§×˜×Ÿ */
    height: 25px; /* ×’×•×‘×” × ××•×š ×™×•×ª×¨ */
    line-height: 1;
    padding: 2px 8px; /* ×¦××¦×•× Padding ×× ×›×™ */
    font-size: 0.8rem;
    border-radius: 4px;
    background-color: #3b82f6; /* ×›×—×•×œ */
    color: white;
    border: none;
    white-space: nowrap;
    width: auto; 
    margin: 0;
}
div.stButton button:hover {
    background-color: #2563eb;
}

/* ğŸ’¡ ×›×œ×œ ×§×¨×™×˜×™: ××›×¨×™×— ××ª ×”×˜×•×¨ ×©×œ ×”×›×¤×ª×•×¨ ×œ×”×ª×™×™×©×¨ ×œ×™××™×Ÿ (Flex-End) */
[data-testid="stColumn"] {
    display: flex;
    flex-direction: column;
    align-items: flex-end; 
}

/* ×•×“× ×©×”×˜×§×¡×˜ ×‘×ª×•×š ×”×˜×•×¨×™× × ×©××¨ ××™×•×©×¨ ×œ×™××™×Ÿ */
[data-testid="stColumn"] > div {
    width: 100%;
    text-align: right;
}

/* ğŸ’¡ ×›×œ×œ×™ ×¦××¦×•× ×¨×•×•×—×™× ×× ×›×™×™× ×‘×™×Ÿ ×”×©××œ×•×ª */
.st-emotion-cache-1r6r8qj { /* ×§×•× ×˜×™×™× ×¨ ×”×¢××•×“×•×ª ×”×¨××©×™ */
    margin-bottom: 0.5rem !important; /* ×¨×•×•×— ×§×˜×Ÿ ×‘×™×Ÿ ×”×©×•×¨×•×ª */
    padding-bottom: 0px !important; 
    padding-top: 0px !important;
}

/* ğŸ’¡ ×¦××¦×•× padding ×‘×ª×•×š ×”-Markdown ×©×œ ×”×©××œ×” */
.st-emotion-cache-1c9v68d { 
    padding-top: 0rem !important;
    padding-bottom: 0rem !important;
    line-height: 1.2; /* ×¦××¦×•× ×’×•×‘×” ×”×©×•×¨×” */
}

</style>
""", unsafe_allow_html=True)

# ============================================
#   ×›×•×ª×¨×ª ×¢×œ×™×•× ×” ×¢× ×œ×•×’×• ×•×˜×§×¡×˜
# ============================================
logo_url = "https://raw.githubusercontent.com/arie5981/faq1/main/logobtl.png"

st.markdown(
    f"""
<div class="header-bar">
  <div style="display:flex; align-items:center; gap:0.6rem;">
    <img src="{logo_url}" class="header-logo" alt="×œ×•×’×• ×”×‘×™×˜×•×— ×”×œ××•××™" />
    <div style="display:flex; flex-direction:column;">
      <span class="header-text-main">×”×‘×™×˜×•×— ×”×œ××•××™</span>
      <span class="header-text-sub">×ª××™×›×” ×œ××ª×¨ ××™×™×¦×’×™× ×‘×’×‘×™×™×”</span>
    </div>
  </div>
</div>
""",
    unsafe_allow_html=True,
)

# ============================================
#   ×§×¨×™××ª ×§×•×‘×¥ faq.txt ××ª×•×š ×”×¨×™×¤×•
# ============================================
FAQ_PATH = "faq.txt"

def read_txt_utf8(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

print("DEBUG 3: ×× ×¡×” ×œ×§×¨×•× ××ª ×§×•×‘×¥ ×”-FAQ.")
try:
    raw_faq = read_txt_utf8(FAQ_PATH)
    print("DEBUG 4: ×§×¨×™××ª ×§×•×‘×¥ FAQ ×”×¦×œ×™×—×”.")
except FileNotFoundError:
    st.error(f"âŒ ×§×•×‘×¥ FAQ ×œ× × ××¦× ×‘× ×ª×™×‘: {FAQ_PATH}. ×•×“× ×©×”×§×•×‘×¥ × ××¦× ×‘×ª×™×§×™×™×” ×”× ×›×•× ×”.")
    st.stop()


# ============================================
#   ×¢×™×‘×•×“ ×”-FAQ ×•×¨×™×›×•×– ×”×§×™×©×•×¨×™×
# ============================================
# [×¤×•× ×§×¦×™×•×ª ×¢×–×¨ × ×©××¨×•×ª ×œ×œ× ×©×™× ×•×™]
def normalize_he(s: str) -> str:
    if not s:
        return ""
    s = unicodedata.normalize("NFC", s)
    s = re.sub(r"[\u200e\u200f]", "", s)
    s = re.sub(r"[^\w\s\u0590-\u05FF]", " ", s)
    s = re.sub(r"\s+", " ", s).strip().lower()
    return s

@dataclass
class FAQItem:
    question: str
    variants: List[str]
    answer: str
    instruction: Optional[str] = None
    contact_details: Optional[dict] = None 

def parse_faq_new(text: str) -> List[FAQItem]:
    items = []
    
    global GLOBAL_CONTACT_DETAILS
    GLOBAL_CONTACT_DETAILS.clear() 

    # 1. ×—×™×œ×•×¥ ×›×œ ×”×§×™×©×•×¨×™× ×”×’×œ×•×‘×œ×™×™× ××›×œ ×”×˜×§×¡×˜
    all_c_matches = re.findall(r">>([^:]+?)\s*:\s*([^<]+?)<<", text)
    GLOBAL_CONTACT_DETAILS = {k.strip(): v.strip() for k, v in all_c_matches}
    
    # 2. ×”×¡×¨×ª ×›×œ ×”×‘×œ×•×§×™× ×©×œ ×”×§×™×©×•×¨×™× ×”×’×œ×•×‘×œ×™×™× ××˜×§×¡×˜ ×”-FAQ
    text_without_links = re.sub(r">>([^:]+?)\s*:\s*([^<]+?)<<", "", text)
    
    # 3. ×¤×™×¦×•×œ ×œ×‘×œ×•×§×™× ×©×œ ×©××œ×•×ª
    blocks = re.split(r"(?=×©××œ×”\s*:)", text_without_links) 

    for b in blocks:
        b = b.strip()
        if not b:
            continue
        
        # [×—×™×œ×•×¥ ×©××œ×”, × ×™×¡×•×—×™×, ×ª×©×•×‘×” ×•×”×•×¨××” × ×©××¨ ×›×¤×™ ×©×”×™×”]
        q_match = re.search(r"×©××œ×”\s*:\s*(.+)", b)
        v_match = re.search(r"(?s)× ×™×¡×•×—×™× ×“×•××™×\s*:\s*(.+?)(?:\n×ª×©×•×‘×”\s*:|\Z)", b)
        a_match = re.search(r"(?s)×ª×©×•×‘×”\s*:\s*(.+?)(?:\n×”×•×¨××”\s*:|\Z)", b)
        i_match = re.search(r"(?s)×”×•×¨××”\s*:\s*(.+?)(?:\n>>|\Z)", b)
        
        question = q_match.group(1).strip() if q_match else ""
        
        answer = ""
        if a_match:
            raw_answer_content = a_match.group(1)
            lines = raw_answer_content.splitlines()
            cleaned_lines = [line.strip() for line in lines]
            answer = '\n'.join(cleaned_lines).strip()
            
        variants = []
        if v_match:
            raw = v_match.group(1)
            variants = [s.strip(" -\t") for s in raw.split("\n") if s.strip()]

        instruction = i_match.group(1).strip() if i_match else None
        
        items.append(FAQItem(question, variants, answer, instruction, contact_details={}))

    return items

print("DEBUG 5: ××ª×—×™×œ × ×™×ª×•×— ×§×•×‘×¥ ×”-FAQ.")
faq_items = parse_faq_new(raw_faq)
print(f"DEBUG 6: × ×™×ª×•×— FAQ ×”×¡×ª×™×™×. × ××¦××• {len(faq_items)} ×©××œ×•×ª.")


# === ×™×¦×™×¨×ª Embeddings + FAISS ===
print("DEBUG 7: ××ª×—×™×œ ×™×¦×™×¨×ª Embeddings ×•-FAISS.")
try:
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small", api_key=openai_api_key)

    docs = []
    for i, item in enumerate(faq_items):
        merged = " | ".join([item.question] + item.variants)
        docs.append(Document(page_content=merged, metadata={"idx": i}))

    faq_store = FAISS.from_documents(docs, embeddings)
    print("DEBUG 8: ×™×¦×™×¨×ª Embeddings ×•-FAISS ×”×¦×œ×™×—×”.")
except Exception as e:
    print(f"FATAL ERROR DEBUG 8: ×©×’×™××” ×‘×™×¦×™×¨×ª Embeddings: {e}")
    st.error(f"âŒ ×©×’×™××” ×—××•×¨×”: ×™×¦×™×¨×ª ××•×“×œ ×”×—×™×¤×•×© × ×›×©×œ×”. ×‘×“×•×§ ××ª ××¤×ª×— ×”-OpenAI ××• ××ª ×¤×•×¨××˜ ×§×•×‘×¥ ×”-FAQ.")
    st.stop()


# [×¤×•× ×§×¦×™×•×ª process_answer_content ×•-search_faq × ×©××¨×•×ª ×œ×œ× ×©×™× ×•×™]
# ============================================
#   ×¤×•× ×§×¦×™×” ×œ×¢×™×‘×•×“ ×ª×•×›×Ÿ ×”×ª×©×•×‘×” (××©×ª××©×ª ×‘×’×œ×•×‘×œ×™)
# ============================================
def process_answer_content(item: FAQItem) -> str:
    global GLOBAL_CONTACT_DETAILS 
    
    answer_text = item.answer.strip()
    
    # 2. ×”×—×œ×¤×ª ××™×œ×•×ª ××¤×ª×— ×‘×§×™×©×•×¨×™ Markdown ×‘×ª×•×š ×”-ANSWER
    if GLOBAL_CONTACT_DETAILS:
        for key, value in GLOBAL_CONTACT_DETAILS.items():
            markdown_link = f"[{key}]({value})"
            answer_text = answer_text.replace(f"[{key}]", markdown_link)
        
        
    # 3. ×˜×™×¤×•×œ ×‘×©×“×” '×”×•×¨××”' ×•×”×•×¡×¤×ª×• ×‘×¡×•×£
    if item.instruction: 
        instruction = item.instruction
        
        # 3×. ×”×—×œ×¤×ª ××™×œ×•×ª ××¤×ª×— ×‘×§×™×©×•×¨×™ Markdown ×‘×ª×•×š ×”×”×•×¨××”
        for key, value in GLOBAL_CONTACT_DETAILS.items():
            markdown_link = f"[{key}]({value})"
            instruction = instruction.replace(f"[{key}]", markdown_link)
        
        answer_text += f"\n\n**×”×¢×¨×•×ª ×•×”×•×¨××•×ª:** {instruction}"

    # ×”×•×¡×¤×ª \n\n ×‘×™×Ÿ ×¤×¡×§××•×ª
    final_content = answer_text.replace('\n', '\n\n')
    return final_content


# ============================================
#   ×—×™×¤×•×© FAQ â€“ fuzzy + embeddings
# ============================================

def search_faq(query: str) -> str:
    nq = normalize_he(query)

    # --- ×—×™×¤×•×© ×¤××–×™ ×¢×œ ×©××œ×•×ª ×•× ×™×¡×•×—×™× ---
    scored = []
    for i, item in enumerate(faq_items):
        all_texts = [item.question] + item.variants
        for t in all_texts:
            score = fuzz.token_sort_ratio(nq, normalize_he(t))
            scored.append((score, i, t))

    scored.sort(reverse=True, key=lambda x: x[0])
    best_score, best_idx, _ = scored[0]

    if best_score >= 80:
        item = faq_items[best_idx]
        final_content = process_answer_content(item)
        return f"{final_content}\n\n××§×•×¨: faq\n\n×©××œ×” ××–×•×”×”: {item.question}"

    # --- fallback: embeddings (×¢× ×©×™×¤×•×¨ × ×™×§×•×“) ---
    hits = faq_store.similarity_search_with_score(query, k=5)
    
    boosted_hits = []
    for doc, score in hits:
        idx = doc.metadata["idx"]
        item = faq_items[idx]
        fuzzy_score = fuzz.token_sort_ratio(nq, normalize_he(item.question))
        boosted_score = (score * 0.7) + (1.0 - (fuzzy_score / 100)) * 0.3
        boosted_hits.append((doc, boosted_score, idx))

    boosted_hits.sort(key=lambda x: x[1])
    
    best_doc, best_score, best_idx = boosted_hits[0]

    if best_score <= 1.1: 
        result_item = faq_items[best_idx]
        
        final_content = process_answer_content(result_item)

        similar_questions = [
            faq_items[d.metadata["idx"]].question
            for d, s, _ in boosted_hits[1:4] 
            if s <= 1.3 and faq_items[d.metadata["idx"]].question.strip() != result_item.question.strip()
        ][:3]
        
        if similar_questions:
            sq_json = json.dumps(similar_questions, ensure_ascii=False)
            final_content += f"\n\n---SIMILAR_QUESTIONS---{sq_json}"

        return f"{final_content}\n\n××§×•×¨: faq\n\n×©××œ×” ××–×•×”×” (×¡×× ×˜×™): {result_item.question}"

    return "×œ× × ××¦××” ×ª×©×•×‘×”, × ×¡×” ×œ× ×¡×— ××ª ×”×©××œ×” ××—×“×©."

# ============================================
#   ×¤×•× ×§×¦×™×™×ª Callback ×œ×˜×™×¤×•×œ ×‘×©×œ×™×—×ª ×”×˜×•×¤×¡ / ×œ×—×™×¦×” ×¢×œ ×©××œ×”
# ============================================
def handle_submit(query_text=None):
    if query_text is None:
        query = st.session_state.query_input
    else:
        query = query_text

    if query:
        st.session_state.messages.append({"role": "user", "content": query})
        answer = search_faq(query)
        st.session_state.messages.append({"role": "assistant", "content": answer})
        st.session_state.query_input = "" 


# ============================================
#   × ×™×”×•×œ ×©×™×—×” ×›××• ChatGPT
# ============================================
print("DEBUG 9: ××ª×—×™×œ × ×™×”×•×œ ××¦×‘ ×”-session.")
if "messages" not in st.session_state:
    st.session_state.messages = []

# ×©××œ×•×ª × ×¤×•×¦×•×ª ×œ××¡×š ×”×¨××©×•×Ÿ
POPULAR_QUESTIONS = [
    "××™×š ××•×¡×™×¤×™× ××©×ª××© ×—×“×© ×‘××ª×¨ ××™×™×¦×’×™×.",
    "××§×‘×œ ×”×•×“×¢×” ×©××—×“ ××• ×™×•×ª×¨ ×× ×ª×•× ×™ ×”×”×–×“×”×•×ª ×©×’×•×™×™×.",
    "××™×š ×™×•×¦×¨×™× ×§×™×¦×•×¨ ×“×¨×š ×œ××ª×¨ ××™×™×¦×’×™× ×¢×œ ×©×•×œ×—×Ÿ ×”×¢×‘×•×“×”.",
    "×¨×•×¦×” ×œ×§×‘×œ ××ª ×”×§×•×“ ×”×—×“ ×¤×¢××™ ×œ×“×•××¨ ××œ×§×˜×¨×•× ×™.",
]

st.markdown("")

# ----------------------------------------------------
# ğŸ’¡ ×”×¦×’×ª ×©××œ×•×ª × ×¤×•×¦×•×ª ×›×¨×©×™××” ×××•×¡×¤×¨×ª ×¢× ×›×¤×ª×•×¨ ×§×˜×Ÿ
# ----------------------------------------------------
print(f"DEBUG 10: ×‘×•×“×§ ××¦×‘ ×”×•×“×¢×•×ª: {len(st.session_state.messages)}")
if len(st.session_state.messages) == 0:
    st.markdown("### ×©××œ×•×ª × ×¤×•×¦×•×ª:")
    print("DEBUG 11: ××ª×—×™×œ ×œ×•×œ××ª ×©××œ×•×ª × ×¤×•×¦×•×ª.")
    
    for i, q in enumerate(POPULAR_QUESTIONS, start=1):
        print(f"DEBUG 12: ××¦×™×’ ×©××œ×” {i}: {q}")
        # ğŸ’¡ ×—×œ×•×§×” ×œ-2 ×¢××•×“×•×ª: ×©××œ×” (80%), ×›×¤×ª×•×¨ (20%) ×¢× gap="small"
        col_q, col_btn = st.columns([0.8, 0.2], gap="small")
        
        with col_q:
            # ğŸ’¡ ×”×¦×’×ª ×”×©××œ×” ×›×—×œ×§ ××¨×©×™××” ×××•×¡×¤×¨×ª
            st.markdown(f"**{i}.** {q}", unsafe_allow_html=True)
            
        with col_btn:
             # ğŸ’¡ ×›×¤×ª×•×¨ ×§×˜×Ÿ ×©×™×•×¦××“ ×œ×©××œ×”
            st.button(
                "×œ×ª×©×•×‘×”", 
                key=f"popular_q_{i}", 
                on_click=handle_submit, 
                args=(q,)
            )

    print("DEBUG 13: ×¡×™×•× ×œ×•×œ××ª ×©××œ×•×ª × ×¤×•×¦×•×ª.")
    st.markdown("## ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?")
    st.markdown("")

# ----------------------------------------------------
# ×ª×™×‘×ª ×”×§×œ×˜
# ----------------------------------------------------
st.markdown('<div class="question-box"></div>', unsafe_allow_html=True)

with st.form("ask_form", clear_on_submit=False): 
    query = st.text_input(" ", 
                          placeholder="×©××œ ×©××œ×” ×•×”×§×© Enter", 
                          key="query_input")
    
    submitted = st.form_submit_button("×©×œ×—", on_click=handle_submit)
print("DEBUG 14: ×¡×™×•× ×”×¦×’×ª ×˜×•×¤×¡ ×”×§×œ×˜.")
# ----------------------------------------------------
# ××¤×¨×™×“ ×•×™×–×•××œ×™ ×‘×™×Ÿ ×˜×•×¤×¡ ×”×§×œ×˜ ×œ×”×™×¡×˜×•×¨×™×”
# ----------------------------------------------------
if len(st.session_state.messages) > 0:
    st.markdown("---") 

# =======================================================================
# ×”×¦×’×ª ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×” ×•×¨×©×™××ª ×©××œ×•×ª ×§×©×•×¨×•×ª
# =======================================================================
print(f"DEBUG 15: ××ª×—×™×œ ×”×¦×’×ª ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×”. ××¡×¤×¨ ×”×•×“×¢×•×ª: {len(st.session_state.messages)}")

user_indices = [i for i, msg in enumerate(st.session_state.messages) if msg["role"] == "user"]

for user_idx in user_indices[::-1]:
    
    # 1. ×”×¦×’×ª ×”×•×“×¢×ª ×”×©××œ×”
    # [×§×•×“ ×”×¦×’×ª ×”×©××œ×”]
    
    # 2. ×”×¦×’×ª ×”×•×“×¢×ª ×”×ª×©×•×‘×” (×× ×§×™×™××ª)
    assistant_idx = user_idx + 1
    if assistant_idx < len(st.session_state.messages):
        # [×§×•×“ ×”×¦×’×ª ×”×ª×©×•×‘×” ×•×”×©××œ×•×ª ×”×§×©×•×¨×•×ª]
        pass
print("DEBUG 16: ×¡×™×•× ×§×•×‘×¥ app.py.")
